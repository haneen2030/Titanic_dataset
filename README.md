# Titanic Dataset – Data Analytics & Machine Learning

# Project Overview

This project explores the famous Titanic dataset, focusing on data preprocessing, feature engineering, and machine learning models to predict passenger survival.
# Dataset

You can download the dataset and explore all the information about it in the following link: https://www.kaggle.com/competitions/titanic/data

# The workflow includes:

- Data cleaning and preprocessing

- Exploratory data analysis (EDA)

- Feature normalization

- Splitting dataset into training and testing sets

- Training different machine learning models

- Evaluating performance metrics

# Dependencies

Make sure you have the following installed:

Python 3.x

pandas

numpy

matplotlib / seaborn (for visualization)

scikit-learn


# Steps in the Notebook

Importing Dependencies – load essential Python libraries.

Reading the Data – load the Titanic dataset into pandas.

Data Preprocessing – handle missing values, encode categorical variables, drop irrelevant columns.

Splitting the Dataset – divide into training and testing sets.

Normalization – scale features for better model performance.

Model Training – train classification models (e.g., Logistic Regression, Random Forest, etc.).

Model Evaluation – compare accuracy, precision, recall, and other metrics.

# Results
Built a model to predict survival.

Evaluated their performance using standard ML metrics.

Highlighted the importance of preprocessing and feature selection.

